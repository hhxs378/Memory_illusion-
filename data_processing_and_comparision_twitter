import numpy as np 
import pandas as pd . 
import string 
from nltk.corpus import stopwords 


def listToString(clean_mess):
    strl =" "
    retrun(strl.join(clean_mess))
    retrun strl
 
def listToString(clean_mess2):
    strl ="  "
    return (strl.join(clean_mess2))
    return strl 

df1=pd.read_csv('MTCH_ronag75_1.csv')

UniqueTweet=df1['friend_tweet'].unique().astype(str)
NumUniquiqueTweet=np.size(UniqueTweet)
print(NumUniqueTweet)

with open('searched_result7.csv','w+') as file: 
     for line in UniqueTweet:
          if "McConnell" in line: 
              alphabet1 = [c for c in line if c not in string.puncuation]
              joined 1= ''.join(alphabet)
              essential1 = [word for word in joined1.split() if word.lower() not in stopwords.words('english')]
              print(essential1)
              file.wirte(line + . ',\t\n')
              
      for line in UniqueTweet:
          if "cocaine" in line: 
              alphabet2 = [c for c in line if c not in string.puncuation]
              joined2 = ''.join(alphabet2)
              essential2 = [word for word in joined2.split() if word.lower() not in stopwords.words('english')]
              print(essential2)
              file.wirte(line + . ',\t\n')
              
  print('done')
  
  
# with open('matched_result.csv','w+') as file:
#      for line in hj:
#          if  "McConnell" in line:
#               file.write(line +',\t\n')
#               print(line)
#               f=line.split(' ')
